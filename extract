import pandas as pd

# On part de df_client avec au moins :
# - client_siren
# - client_id
# - client_organism
# - client_creation_date

# 1) On s'assure que la date de création est bien en datetime
df_client["client_creation_date"] = pd.to_datetime(
    df_client["client_creation_date"], errors="coerce"
)

# 2) Créer une colonne "id|organisme" en vectoriel (très rapide)
#    - on remplace les NaN par "" pour éviter "nan" dans les chaînes
tmp = df_client.copy()

tmp["client_id_str"] = tmp["client_id"].astype("string")          # string pandas (gère les NaN)
tmp["client_organism_str"] = tmp["client_organism"].astype("string")

tmp["client_id_str"] = tmp["client_id_str"].fillna("")
tmp["client_organism_str"] = tmp["client_organism_str"].fillna("")

# Concaténation vectorielle "id|organisme"
tmp["id_org"] = tmp["client_id_str"] + "|" + tmp["client_organism_str"]

# 3) On enlève les doublons SIREN / id_org pour éviter de répéter les mêmes couples
tmp_unique = tmp.drop_duplicates(subset=["client_siren", "id_org"])

# 4) Construire client_organism_map par groupby + join (tout en vectoriel)
#    - on trie pour avoir un ordre stable
id_org_map = (
    tmp_unique
    .sort_values(["client_siren", "id_org"])
    .groupby("client_siren")["id_org"]
    .apply("; ".join)   # concatène tous les id_org d'un SIREN avec "; "
    .rename("client_organism_map")
)

# 5) Calculer la dernière date de création par SIREN
last_creation = (
    df_client
    .groupby("client_siren")["client_creation_date"]
    .max()
    .rename("last_creation_date")
)

# 6) Assembler dans un df agrégé par SIREN
df_client_agg = (
    pd.concat([id_org_map, last_creation], axis=1)
    .reset_index()
    .rename(columns={"client_siren": "SIREN"})
)
