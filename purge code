# ==== OPTI MÉMOIRE : dtypes utiles ====
# Aligne les dtypes et réduit la mémoire
if df_request["request_status"].dtype != "category":
    df_request["request_status"] = df_request["request_status"].astype("category")

# S'assure que les id ont le même dtype pour le mapping
df_request["request_client_id"] = df_request["request_client_id"].astype(df_client["client_id"].dtype, copy=False)

# ==== HASH MAP client_id -> SIREN (aucun merge de 4M lignes) ====
siren_map = pd.Series(df_client["client_siren"].values, index=df_client["client_id"].values)

# -----------------------------
# RÈGLE 2 : aucune demande modifiée dans les 12 derniers mois
# -----------------------------
# Agrégat par client_id (réduit fort le volume vs 4M lignes)
last_mod_by_client = (
    df_request
    .groupby("request_client_id", observed=True)["request_last_modification_date"]
    .max()
)

# map client -> SIREN, puis agrégat par SIREN
last_mod_by_siren = (
    last_mod_by_client
    .rename("req_last_mod_max")
    .to_frame()
    .assign(SIREN=lambda d: siren_map.reindex(d.index).values)
    .dropna(subset=["SIREN"])  # ignore clients sans SIREN pour l'agrégat
    .groupby("SIREN", observed=True)["req_last_mod_max"].max()
)

# Construction du flag_2 (si pas de demande pour un SIREN, on considère True)
r2 = (
    last_mod_by_siren
    .reindex(tiers_flags["SIREN"])  # assure même univers de SIREN
    .to_frame()
    .assign(flag_2_no_req_12m=lambda d: d["req_last_mod_max"].lt(cutoff_12m) | d["req_last_mod_max"].isna())
    .reset_index()[["SIREN", "flag_2_no_req_12m"]]
)

# -----------------------------
# RÈGLE 3 : demandes ACC modifiées il y a ≥ 6 ans
# -----------------------------
# On filtre d'abord ACC (réduit fortement le volume)
req_acc = df_request[df_request["request_status"] == "ACC"]

# Agrégat par client_id
acc_last_mod_by_client = (
    req_acc
    .groupby("request_client_id", observed=True)["request_last_modification_date"]
    .max()
)

# map client -> SIREN, puis agrégat par SIREN
acc_last_mod_by_siren = (
    acc_last_mod_by_client
    .rename("acc_last_mod_max")
    .to_frame()
    .assign(SIREN=lambda d: siren_map.reindex(d.index).values)
    .dropna(subset=["SIREN"])
    .groupby("SIREN", observed=True)["acc_last_mod_max"].max()
)

# Si pas de demande ACC pour un SIREN → True
r3 = (
    acc_last_mod_by_siren
    .reindex(tiers_flags["SIREN"])  # inclut SIREN sans ACC (NaN)
    .to_frame()
    .assign(flag_3_ACC_6y=lambda d: d["acc_last_mod_max"].le(cutoff_6y))
    .assign(flag_3_ACC_6y=lambda d: d["flag_3_ACC_6y"].fillna(True))
    .reset_index()[["SIREN", "flag_3_ACC_6y"]]
)

# -----------------------------
# Réinjecte ces flags sans faire de gros merges coûteux
# -----------------------------
tiers_flags = (
    tiers_flags
    .drop(columns=[c for c in ["flag_2_no_req_12m", "flag_3_ACC_6y"] if c in tiers_flags], errors="ignore")
    .merge(r2, on="SIREN", how="left")
    .merge(r3, on="SIREN", how="left")
)

# Valeurs manquantes → True (cas "pas de données")
for c in ["flag_2_no_req_12m", "flag_3_ACC_6y"]:
    tiers_flags[c] = tiers_flags[c].fillna(True).astype(int)

# Recalcule le flag final si besoin
tiers_flags["flag_eligible_purge"] = (
    tiers_flags[["flag_1_TER_6y", "flag_2_no_req_12m", "flag_3_ACC_6y", "flag_4_contentieux_arch_6y"]]
    .all(axis=1)
    .astype(int)
)
